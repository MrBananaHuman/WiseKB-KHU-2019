# Network
encoder_type:
decoder_type: AttnDecoderRNN #InputFeedDecoder, AttnDecoderRNN, ScheduledDecoder
rnn_type: GRU #RNN, LSTM, GRU
bidirectional: true
embedding_size: 500 #500
hidden_size: 500 #500
num_layers: 2
dropout: 0.3 #0.3
dropout_ev: 0.3 #0.3
atten_model: dot #general, dot, none  !!!!! base use dot 

dhidden_size: 128 #128
aux_size: 256
aux_nums: 4

mem_gate: true
gate_vector: true
src_attention: true #t

# Misc
use_cuda: true
random_seed: 940203

# Train
optim_method: adam #adadelta, adam, sgd
max_grad_norm: 5 #5
learning_rate_R: 0.001 #0.001
learning_rate_T: 0.001 #0.001
learning_rate_C: 0.001 #0.001
learning_rate_decay: 0.9
start_decay_at: 8
weight_decay: 0.000001 #  weight decay(L2 penalty)
num_train_epochs: 100
steps_per_stats: 100
steps_per_eval: 1000 #1000
train_batch_size: 128  #128 ->  64
train_shard_size: 32 #32 -> 32
start_epoch_at: 
valid_batch_size: 32  #32 -> 16


use_ev: false #f
use_critic: true #f
out_dir: ./out/1113_Shop_60 # path to save model
